{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHLyOdYUayI6J5MZ6VIeEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahnamaRad/ALO/blob/master/fast_ALO_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA0BsSj4VJUn",
        "outputId": "1dd7ba7d-3d75-47de-fdaa-b531a04c2f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder does not exist\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "folder_path = '/content/fast-ALO'  # Replace 'my_folder' with the path to your directory\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(\"Folder removed successfully\")\n",
        "else:\n",
        "    print(\"Folder does not exist\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "!git clone https://github.com/RahnamaRad/fast-ALO\n",
        "\n",
        "# Change the current directory to the cloned repository\n",
        "os.chdir('fast-ALO')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hWGsYUVeBl",
        "outputId": "5aedd723-af66-49ce-8723-20089cdd4b37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-ALO'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 32 (delta 16), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (32/32), 2.80 MiB | 13.81 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import laplace, norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import diags\n",
        "from scipy.sparse.linalg import cg, LinearOperator, inv\n",
        "from time import time  # Make sure to import the time function\n",
        "\n",
        "def create_sparse_D_matrix(p):\n",
        "    # Diagonal elements\n",
        "    diagonal = np.ones(p-1)\n",
        "    # Off-diagonal elements\n",
        "    off_diagonal = -1 * np.ones(p-1)\n",
        "    # Create sparse matrix with diagonal and off-diagonal\n",
        "    D = diags([diagonal, off_diagonal], [0, 1], shape=(p-1, p))\n",
        "    return D\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "np.random.seed(1)\n",
        "# Parameters\n",
        "logp_       = np.arange(0,4)\n",
        "plogstep    = 2\n",
        "p_          = 500* plogstep**(logp_)\n",
        "p_          = p_.astype(int)\n",
        "delta       = 1 # n/p\n",
        "lm          = 10\n",
        "S           = 250  # Number of iterations/samples\n",
        "# Vectors of zeros\n",
        "ALO           = []  # Creates a column vector of zeros of length m\n",
        "ALO_fast      = []   # Same as above\n",
        "TRAIN         = []  # Same as above\n",
        "timeALO       = [] # Creates a column vector of zeros of length m\n",
        "timeALO_fast  = []   # Same as above\n",
        "timeTRAIN     = []  # Same as above\n",
        "\n",
        "# Define the matrix-vector product function outside the loop\n",
        "def matvec(v, X, D, lambda_reg):\n",
        "    return X.T @ (X @ v) + lambda_reg * (D.T @ (D @ v))\n",
        "\n",
        "\n",
        "# Generate data and fit model\n",
        "for i, p in enumerate(p_):\n",
        "    n = int(p * delta)\n",
        "    X = np.random.normal(0, 1/np.sqrt(n), (n, p))\n",
        "    D = create_sparse_D_matrix(p)\n",
        "    m = D.shape[0]\n",
        "    # Arrays to store results\n",
        "    b_s1        = np.zeros((p, S))  # to store results of X.T @ e_s1\n",
        "    b_s2        = np.zeros((p, S))  # to store results of D.T @ e_s2\n",
        "    u_s         = np.zeros((p, S))\n",
        "    Hii         = np.zeros((p, lm))\n",
        "    Hii_fast    = np.zeros((p, lm))\n",
        "    for s in range(S):\n",
        "        # Compute b_s1 and b_s2\n",
        "        # Sample e_s1, e_s2 from N(0, I)\n",
        "        e_s1 = np.random.normal(0, 1, n)\n",
        "        e_s2 = np.random.normal(0, 1, m)\n",
        "        b_s1[:, s] = X.T @ e_s1  # Compute X^T @ e_s1\n",
        "        b_s2[:, s] = D.T @ e_s2  # Compute D^T @ e_s2\n",
        "        #if i > 0:\n",
        "        #if s % 100 == 99:  # Print every 100 iterations of s\n",
        "         #   print(f\"p= {p:4d}| s={s+1:3d}| df={df:.2f}, lmb={lambdaS[0]*n:.1f}| lo={lo[s, i]:.2f}| outErr={outErr[s, i]:.2f}| MSE ={MSE[i]:.3f} | scaling = {a:.2f} | R2_MSE = {R2:.2f}| res=  {np.mean(np.abs(res)):.4f}|r1 = {np.mean(np.abs(r1)):.4f}| r2 = {np.mean(np.abs(r2)):.4f}\")\n",
        "\n",
        "    # Loop over different lambda values\n",
        "    for lambda_reg in lambdas:\n",
        "        # Define shape of A for the LinearOperator with the current lambda\n",
        "        A = LinearOperator((p, p), matvec=lambda v: matvec(v, X, D, lambda_reg))\n",
        "        b = b_s1 + lambda_reg * b_s2\n",
        "        # Start timing - TRAIN\n",
        "        tstart = time()\n",
        "        # Solve for y using conjugate gradient\n",
        "        z, exit_code = cg(A, b, x0=z, tol=tol, maxiter=maxiter)\n",
        "        # End timing\n",
        "        fit_time = time() - tstart\n",
        "        timeTRAIN.append(fit_time)  # Store the fitting time\n",
        "        mse = np.mean((r - (X @ z))**2)\n",
        "        TRAIN.append(mse)\n",
        "\n",
        "    # Start timing - ALO\n",
        "    tstart = time()\n",
        "    diag_inv = np.zeros((n2,1))\n",
        "    for i in range(n2):\n",
        "        # Create the i-th unit vector in sparse format\n",
        "        e_i = csr_matrix((np.array([1]), ([i], [0])), shape=(n2,1))\n",
        "        e_i = e_i.toarray().ravel()\n",
        "        # Solve A x = e_i\n",
        "        # Since e_i is a 1xN matrix, we need to flatten it to make it a proper vector\n",
        "        ae, exit_code = cg(A, e_i, tol=tol, maxiter=maxiter)\n",
        "        if exit_code == 0:\n",
        "            # The i-th diagonal element of A^{-1} is the i-th element of ae\n",
        "            diag_inv[i] = ae[i]\n",
        "            e = A @ ae\n",
        "            #if (np.sum(abs(A @ ae- e_i)) > 0.001):\n",
        "            #    print(np.sum(abs(A @ ae- e_i)))\n",
        "        else:\n",
        "            raise Exception(f\"CG did not converge for the {i}-th unit vector\")\n",
        "    hh = np.zeros((T,1))\n",
        "    for t in range(T):\n",
        "        hh[t] = diag_inv[I[t]]\n",
        "    # End timing\n",
        "    alo_time = time() - tstart\n",
        "    timeALO.append(alo_time)  # Store the fitting time\n",
        "    alo     = np.mean(((r - (X @ z) ) / (1 - hh)) **2)\n",
        "    ALO.append(alo)\n",
        "    Hii[:, lmi] = diag_inv.flatten()\n",
        "\n",
        "    # Start timing - fast ALO\n",
        "    tstart = time()\n",
        "    b_s = b_s1 +  np.sqrt(lambda_reg) * b_s2\n",
        "    # Solve the system A x = b for each column of b_s\n",
        "    for s in range(S):\n",
        "        u_, info = cg(A, b_s[:, s], tol=tol, x0=u_s[:, s])\n",
        "        if info == 0:\n",
        "            u_s[:, s] = u_\n",
        "        else:\n",
        "            print(f\"CG did not converge for column {s}\")\n",
        "    #XU = X @ u_s\n",
        "    #Z =  (u_s @ u_s.T) / S\n",
        "    # Step 1: Center the data\n",
        "    means = np.mean(u_s, axis=1, keepdims=True)\n",
        "    u_s_centered = u_s - means\n",
        "    # Step 2: Compute the covariance matrix\n",
        "    Z =  np.dot(u_s_centered, u_s_centered.T) / (S - 1)\n",
        "    #for l in range(4):\n",
        "     #   Z  = 2*Z - Z @ (A @ Z)\n",
        "    diag_inv_ = Z.diagonal()\n",
        "    Hii_fast[:, lmi] = diag_inv_\n",
        "    Z  = (X @ Z) @ X.T\n",
        "    hh_fast = np.diag(Z)\n",
        "\n",
        "    #print(hh_fast)\n",
        "    #np.var(XU, axis=1, ddof=1)  # ddof=1 uses (S-1) in the denominator\n",
        "    # End timing\n",
        "    alo_fast_time = time() - tstart\n",
        "    timeALO_fast.append(alo_fast_time)  # Store the fitting time\n",
        "    alo_fast     = np.mean(((r - (X @ z)) / (1 - hh_fast)) **2)\n",
        "    ALO_fast.append(alo_fast)\n",
        "    print(f\"lambda = {lambda_reg:.2f}| alo={alo:.2f}| alo time ={alo_time:.0f}| alo_fast={alo_fast:.2f}| alo_fast time ={alo_fast_time:.0f}| mse={mse:.2f}| fit time = {fit_time:.2f}| h ={np.mean(hh):.2f}| max_err ={np.max(abs(diag_inv_ - diag_inv)):.2f}| mean_err ={np.mean(abs(diag_inv_ - diag_inv)):.2f}\")\n",
        "    lmi = lmi + 1\n",
        "\n",
        "# Ensure all arrays are numpy arrays for easier handling\n",
        "fit_times = np.array(timeTRAIN)\n",
        "tt=np.mean(fit_times)\n",
        "\n",
        "    # Collect results for the DataFrame\n",
        "    MSE_SE[i] = np.std((lo[:, i] - outErr[:, i]) ** 2) / np.sqrt(MCMCsamples)\n",
        "    results.append({\n",
        "        'delta': delta,\n",
        "        'rho': rho,\n",
        "        'alpha_elnet': alpha_elnet,\n",
        "        'n': n,\n",
        "        'p': p,\n",
        "        'MSE': MSE[i],\n",
        "        'bias': bias[i],\n",
        "        'var': var[i],\n",
        "        'MSE_SE': MSE_SE[i]\n",
        "    })\n",
        "\n",
        "ls_mse_fit = sm.OLS(np.log(MSE), sm.add_constant(np.log(p_))).fit()\n",
        "a_mse = ls_mse_fit.params[1]\n",
        "R2_mse = ls_mse_fit.rsquared\n",
        "\n",
        "ls_var_fit = sm.OLS(np.log(var), sm.add_constant(np.log(p_))).fit()\n",
        "a_var = ls_var_fit.params[1]\n",
        "R2_var = ls_var_fit.rsquared\n",
        "\n",
        "bias2 = bias**2\n",
        "ls_bias2_fit = sm.OLS(np.log(bias2), sm.add_constant(np.log(p_))).fit()\n",
        "a_bias2 = ls_bias2_fit.params[1]\n",
        "R2_bias2 = ls_bias2_fit.rsquared\n",
        "\n",
        "print(f\" MSE: scaling = {a_mse:.2f} | R2 = {R2_mse:.2f}\")\n",
        "print(f\" var: scaling = {a_var:.2f} | R2 = {R2_var:.2f}\")\n",
        "print(f\" bias2: scaling = {a_bias2:.2f} | R2 = {R2_bias2:.2f}\")\n",
        "\n",
        "# Calculate MSE standard error\n",
        "MSE_SE = np.std((lo - outErr) ** 2, axis=0) / np.sqrt(MCMCsamples)\n",
        "print(\"Mean squared errors:\", np.mean((lo - outErr) ** 2, axis=0))\n",
        "print(\"MSE standard errors:\", MSE_SE)\n",
        "\n",
        "# Convert results to a NumPy array\n",
        "results_array = np.array(results)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "filename = f'linearELNET_{\"pos\" if pos else \"neg\"}.npy'\n",
        "\n",
        "if alpha_elnet == 1:\n",
        "  filename = f'linearLASSO_{\"pos\" if pos else \"neg\"}.npy'\n",
        "\n",
        "np.save(filename, results_array, allow_pickle=True)\n",
        "\n",
        "files.download(filename)\n"
      ],
      "metadata": {
        "id": "SKGSJeWcVuXT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}